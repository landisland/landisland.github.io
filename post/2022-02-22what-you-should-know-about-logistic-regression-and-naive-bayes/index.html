<!DOCTYPE html>
<html lang="en" dir="auto">

<head>

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>What You Should Know About Logistic Regression and Naive Bayes | Landisland</title>
<meta name="keywords" content="Statistics" />
<meta name="description" content="Some take outs from machine learning">
<meta name="author" content="">
<link rel="canonical" href="/post/2022-02-22what-you-should-know-about-logistic-regression-and-naive-bayes/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.c88963fe2d79462000fd0fb1b3737783c32855d340583e4523343f8735c787f0.css" integrity="sha256-yIlj/i15RiAA/Q&#43;xs3N3g8MoVdNAWD5FIzQ/hzXHh/A=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.91.2" />
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="What You Should Know About Logistic Regression and Naive Bayes" />
<meta property="og:description" content="Some take outs from machine learning" />
<meta property="og:type" content="article" />
<meta property="og:url" content="/post/2022-02-22what-you-should-know-about-logistic-regression-and-naive-bayes/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-02-22T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2022-02-22T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="What You Should Know About Logistic Regression and Naive Bayes"/>
<meta name="twitter:description" content="Some take outs from machine learning"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "/post/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "What You Should Know About Logistic Regression and Naive Bayes",
      "item": "/post/2022-02-22what-you-should-know-about-logistic-regression-and-naive-bayes/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "What You Should Know About Logistic Regression and Naive Bayes",
  "name": "What You Should Know About Logistic Regression and Naive Bayes",
  "description": "Some take outs from machine learning",
  "keywords": [
    "Statistics"
  ],
  "articleBody": "Bayes rule: type of a generative classifier (Bayes Classifier) We use Bayes rule as the basis for designing algorithms, as follows:\nGiven that we wish to learn some target function $f: X \\rightarrow Y$, or equivalently, $P(Y \\mid X)$, we use the training data to learn estimates of $P(X \\mid Y)$ and $P(Y)$. New $X$ examples can then be classified using these estimated probability distributions, plus Bayes rule. This type of classifier is called a generative classifier, because we can view the distribution $P(X \\mid Y)$ as describing how to generate random instances $X$ conditioned on the target attribute $Y$.\nBayes classifier is unrealistic, and then we have Naive Bayes classifier Learning Bayes classifiers typically requires an unrealistic number of training examples (i.e., more than $|X|$ training examples where $X$ is the instance space) unless some form of prior assumption is made about the form of $P(X \\mid Y)$. The Naive Bayes classifier assumes all attributes describing $X$ are conditionally independent given $Y$. This assumption dramatically reduces the number of parameters that must be estimated to learn the classifier. Naive Bayes is a widely used learning algorithm, for both discrete and continuous $X$.\nWhen $X$ is a vector of discrete-valued attributes, Naive Bayes learning algorithms can be viewed as linear classifiers; that is, every such Naive Bayes classifier corresponds to a hyperplane decision surface in $X$. The same statement holds for Gaussian Naive Bayes classifiers if the variance of each feature $i$ is assumed to be independent of the class $k$ (i.e., if $\\sigma_{i k}=\\sigma_{i}$ ).\nLogistic regression: type of a discriminative classifier Logistic Regression is a function approximation algorithm that uses training data to directly estimate $P(Y \\mid X)$, in contrast to Naive Bayes. In this sense, Logistic Regression is often referred to as a discriminative classifier because we can view the distribution $P(Y \\mid X)$ as directly discriminating the value of the target value $Y$ for any given instance $X$.\nLogistic regression and Gaussian naive bayes Logistic Regression is a linear classifier over $X .$ The linear classifiers produced by Logistic Regression and Gaussian Naive Bayes are identical in the limit as the number of training examples approaches infinity, provided the Naive Bayes assumptions hold. However, if these assumptions do not hold, the Naive Bayes bias will cause it to perform less accurately than Logistic Regression, in the limit. Put another way, Naive Bayes is a learning algorithm with greater bias, but lower variance, than Logistic Regression. If this bias is appropriate given the actual data, Naive Bayes will be preferred. Otherwise, Logistic Regression will be preferred.\nSummary We can view function approximation learning algorithms as statistical estimators of functions, or of conditional distributions $P(Y \\mid X)$. They estimate $P(Y \\mid X)$ from a sample of training data. As with other statistical estimators, it can be useful to characterize learning algorithms by their bias and expected variance, taken over different samples of training data.\nReference\n",
  "wordCount" : "487",
  "inLanguage": "en",
  "datePublished": "2022-02-22T00:00:00Z",
  "dateModified": "2022-02-22T00:00:00Z",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/post/2022-02-22what-you-should-know-about-logistic-regression-and-naive-bayes/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Landisland",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="Landisland (Alt + H)">Landisland</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="/categories" title="Categories">
                    <span>Categories</span>
                </a>
            </li>
            <li>
                <a href="/notes/" title="Notes">
                    <span>Notes</span>
                </a>
            </li>
            <li>
                <a href="/archives" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://landisland.zhubai.love/" title="Newsletter(Chinese)">
                    <span>Newsletter(Chinese)</span>
                </a>
            </li>
            <li>
                <a href="/tags" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="/about" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">



<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      What You Should Know About Logistic Regression and Naive Bayes
    </h1>
    <div class="post-meta"><span title='2022-02-22 00:00:00 +0000 UTC'>February 22, 2022</span>

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#bayes-rule-type-of-a-generative-classifier-bayes-classifier" aria-label="Bayes rule: type of a generative classifier (Bayes Classifier)">Bayes rule: type of a generative classifier (Bayes Classifier)</a></li>
                <li>
                    <a href="#bayes-classifier-is-unrealistic-and-then-we-have-naive-bayes-classifier" aria-label="Bayes classifier is unrealistic, and then we have Naive Bayes classifier">Bayes classifier is unrealistic, and then we have Naive Bayes classifier</a></li>
                <li>
                    <a href="#logistic-regression-type-of-a-discriminative-classifier" aria-label="Logistic regression: type of a discriminative classifier">Logistic regression: type of a discriminative classifier</a></li>
                <li>
                    <a href="#logistic-regression-and-gaussian-naive-bayes" aria-label="Logistic regression and Gaussian naive bayes">Logistic regression and Gaussian naive bayes</a></li>
                <li>
                    <a href="#summary" aria-label="Summary">Summary</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h3 id="bayes-rule-type-of-a-generative-classifier-bayes-classifier">Bayes rule: type of a generative classifier (Bayes Classifier)<a hidden class="anchor" aria-hidden="true" href="#bayes-rule-type-of-a-generative-classifier-bayes-classifier">#</a></h3>
<p>We use Bayes rule as the basis for designing algorithms, as follows:</p>
<p>Given that we wish to learn some target function $f: X \rightarrow Y$, or equivalently, $P(Y \mid X)$, we use the training data to learn estimates of $P(X \mid Y)$ and $P(Y)$. New $X$ examples can then be classified using these estimated probability distributions, plus Bayes rule. This type of classifier is called a <strong>generative classifier</strong>, because we can view the distribution $P(X \mid Y)$ as describing how to generate random instances $X$ conditioned on the target attribute $Y$.</p>
<h3 id="bayes-classifier-is-unrealistic-and-then-we-have-naive-bayes-classifier">Bayes classifier is unrealistic, and then we have Naive Bayes classifier<a hidden class="anchor" aria-hidden="true" href="#bayes-classifier-is-unrealistic-and-then-we-have-naive-bayes-classifier">#</a></h3>
<p>Learning Bayes classifiers typically requires an unrealistic number of training examples (i.e., more than $|X|$ training examples where $X$ is the instance space) unless some form of prior assumption is made about the form of $P(X \mid Y)$. <strong>The Naive Bayes classifier assumes all attributes describing $X$ are conditionally independent given $Y$.</strong> This assumption dramatically reduces the number of parameters that must be estimated to learn the classifier. Naive Bayes is a widely used learning algorithm, for both discrete and continuous $X$.</p>
<p>When $X$ is a vector of discrete-valued attributes, Naive Bayes learning algorithms can be viewed as linear classifiers; that is, every such Naive Bayes classifier corresponds to a hyperplane decision surface in $X$. The same statement holds for Gaussian Naive Bayes classifiers if the variance of each feature $i$ is assumed to be independent of the class $k$ (i.e., if $\sigma_{i k}=\sigma_{i}$ ).</p>
<h3 id="logistic-regression-type-of-a-discriminative-classifier">Logistic regression: type of a discriminative classifier<a hidden class="anchor" aria-hidden="true" href="#logistic-regression-type-of-a-discriminative-classifier">#</a></h3>
<p>Logistic Regression is a function approximation algorithm that uses training data to directly estimate $P(Y \mid X)$, in contrast to Naive Bayes. In this sense, <strong>Logistic Regression is often referred to as a discriminative classifier because we can view the distribution $P(Y \mid X)$ as directly discriminating the value of the target value $Y$ for any given instance $X$.</strong></p>
<h3 id="logistic-regression-and-gaussian-naive-bayes">Logistic regression and Gaussian naive bayes<a hidden class="anchor" aria-hidden="true" href="#logistic-regression-and-gaussian-naive-bayes">#</a></h3>
<p>Logistic Regression is a linear classifier over $X .$ The linear classifiers produced by Logistic Regression and Gaussian Naive Bayes are identical in the limit as the number of training examples approaches infinity, provided the Naive Bayes assumptions hold. However, if these assumptions do not hold, the Naive Bayes bias will cause it to perform less accurately than Logistic Regression, in the limit. Put another way, Naive Bayes is a learning algorithm with greater bias, but lower variance, than Logistic Regression. If this bias is appropriate given the actual data, Naive Bayes will be preferred. Otherwise, Logistic Regression will be preferred.</p>
<h3 id="summary">Summary<a hidden class="anchor" aria-hidden="true" href="#summary">#</a></h3>
<p>We can view function approximation learning algorithms as statistical estimators of functions, or of conditional distributions $P(Y \mid X)$. They estimate $P(Y \mid X)$ from a sample of training data. As with other statistical estimators, it can be useful to characterize learning algorithms by their bias and expected variance, taken over different samples of training data.</p>
<p><a href="https://www.cs.cmu.edu/~tom/mlbook/NBayesLogReg.pdf">Reference</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="/tags/statistics/">statistics</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="/">Landisland</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>

    <br>
    <span>All Conetents Are Licensed Under <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="nooopener noreferrer" target="_blank">CC BY-NC 4.0</a> Unless Otherwise Stated</span>
    <br>
    

</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
