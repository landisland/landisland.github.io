[{"content":"Machine Learning Process flowchart LR; id1(Business Understanding) --\u0026gt; id2(Data Understanding) --\u0026gt; id3(Data Preparation) --\u0026gt; id4(Modeling) --\u0026gt; id5(Evaluation) --\u0026gt; id6(Deployment) EDA: One of data preparation processes EDA is abbreviation of Exploratory Data Analysis, during this process:\n Understanding the given dataset and helps clean up the given dataset. It gives you a clear picture of the features and the relationships between them. Providing guidelines for essential variables and leaving behind/removing non-essential variables. Handling Missing values or human error. Identifying outliers. EDA process would be maximizing insights of a dataset.  ","permalink":"/post/2022-01-26machine-learning-process/","summary":"Process of machine learning","title":"Machine Learning Process"},{"content":"From Medium Phani Srikanth\nThe basic difference between K-NN classifier and Naive Bayes classifier is that the former is a discriminative classifier but the latter is a generative classifier.\nGoing into specifics, K-NN classifier is a supervised lazy classifier which has local heuristics. Being a lazy classifier, it is difficult to use this for prediction in real time. The decision boundaries you achieve with K-NN are much more complex than any decision trees, thus obtaining a nice classification. When you are solving a problem which directly focusses on finding similarity between observations. K-NN does better because of its inherent nature to optimize locally. This is also a flipside because, outliers can significantly kill the performance. Additionally, K-NN is most likely to overfit, and hence adjusting k to maximize test set performance is the way to go. As the complexity of the space grows, the accuracy of K-NN comes down and you would need more data, but the order of this classifier is $n^2$ and it becomes too slow. So, a dimensionality reduction technique like PCA, SVD etc are typically applied and subsequently this classifier is used.\nNaive Bayes is an eager learning classifier and it is much faster than K-NN. Thus, it could be used for prediction in real time. Typically, email spam filtering uses Naive Bayes classifier. It takes a probabilistic estimation route and generates probabilities for each class. It assumes conditional dependence between the features and uses a maximum likelihood hypothesis. The best part with this classifier is that, it learns over time. In a spam filtering task, the type of spam words in email evolves over time. In the same way, the classifier also calculates probability estimates for the newly occurring spam words in a\u0026quot;bag of words\u0026quot;model and makes sure it performs well. This feature of the classifier is due to the inherent nature of the algorithm being generative and not discriminative.\nWhy Naive Bayes is Naive? Because Naive Bayes does not care word orders.\nFor more info click here\n","permalink":"/post/2022-01-26naive-bayes-and-k-nn/","summary":"Process of machine learning","title":"Naive Bayes and K-NN"},{"content":"How does KNN algorithm work? The letter \u0026ldquo;K\u0026rdquo; in KNN means the number of neighbors  around the test sample. During prediction it searches for the nearest neighbors and takes their majority vote as the class predicted for the sample.\nflowchart LR id1(For a sample) --\u0026gt; id2(Find its k nearest neighbor) --\u0026gt; id3(Take majority vote as sample class predicted for the sample) Find neighbor: distance/similarity metric (some norms) Minikowski distance $$ D(X, Y)=\\left(\\sum_{i=1}^{n}\\left|x_{i}-y_{i}\\right|^{p}\\right)^{\\frac{1}{p}} $$\n(Norm $l_0$) Matthan distrance (Norm $l_1$, $p=1$) $$ D(X, Y)=\\left(\\sum_{i=1}^{n}\\left|x_{i}-y_{i}\\right|\\right) $$\nEuclidean distance (Norm $l_2$, $p=2$) $$ D(X, Y)=\\left(\\sum_{i=1}^{n}\\left|x_{i}-y_{i}\\right|^{2}\\right)^{\\frac{1}{2}} $$\nL-infinity distance (Norm $l_\\infty$) $$ D(X, Y)=\\text{max}\\left|x_{i}-y_{i}\\right| $$\nL-negative-infinity distance (Norm $l_\\infty$) $$ D(X, Y)=\\text{min}\\left|x_{i}-y_{i}\\right| $$\nFeature scaling - Normalization Why Normalization?\n To avoid bias towards variables with higher magnitude\n Standard score $$ f_{i} \\leftarrow \\frac{f_{i}-\\mu_{i}}{\\sigma_{i}} $$\n  Represents the feature value in terms of $\\sigma$ units from mean\n  Works well for populations that are normally distributed\n  Min-max feature scaling $$ f_{i} \\leftarrow \\frac{f_{i}-f_{\\min }}{f_{\\max }-f_{\\min }} $$\n Set all feature values within [0,1] range  Three KNN algorithms: Brute force, Ball tree, and k-d tree Brute force method Training time complexity: $O(1)$\nTraining space complexity: $O(1)$\nPrediction time complexity: $O(knd)$\n​\teach sample, calculate d times to get distance, then we have n sample, thus n*d, finally we have k samples need to be found, hence $knd$.\nPrediction space complexity: $O(1)$\nTraining phase technically does not exist, since all computation is done during prediction, so we have O(1) for both time and space.\nPrediction phase is, as method name suggest, a simple exhaustive search, which in pseudocode is:\nLoop through all points k times:\n1. Compute the distance between currently classifier sample and training points, remember the index of the element with the smallest distance (ignore previously selected points) 2. Add the class at found index to the counter Return the class with the most votes as a prediction This is a nested loop structure, where the outer loop takes k steps and the inner loop takes n steps. 3rd point is $O(1$) and 4th is $O(\\text{number of classes})$, so they are smaller. Additionally, we have to take into consideration the numer of dimensions d, more directions mean longer vectors to compute distances. Therefore, we have $O(n * k * d)$ time complexity.\nAs for space complexity, we need a small vector to count the votes for each class. It’s almost always very small and is fixed, so we can treat it as a O(1) space complexity.\nBall tree method Training time complexity: $O(d * n * log(n))$\nTraining space complexity: $O(d * n)$\nPrediction time complexity: $O(k * log(n))$\nPrediction space complexity: $O(1)$\nBall tree algorithm takes another approach to dividing space where training points lie. In contrast to k-d trees, which divides space with median value “cuts”, ball tree groups points into “balls” organized into a tree structure. They go from the largest (root, with all points) to the smallest (leaves, with only a few or even 1 point). It allows fast nearest neighbor lookup because nearby neighbors are in the same or at least close “balls”.\nDuring the training phase, we only need to construct the ball tree. There are a few algorithms for constructing the ball tree, but the one most similar to k-d tree (called “k-d construction algorithm” for that reason) is $O(d * n * log(n))$, the same as k-d tree.\nBecause of the tree building similarity, the complexities of the prediction phase are also the same as for k-d tree.\nk-d tree method Check a demonstration video here.\nTraining time complexity: $O(d * n * log(n))$\nTraining space complexity: $O(d * n)$\nPrediction time complexity: $O(k * log(n))$\nPrediction space complexity: $O(1)$\nDuring the training phase, we have to construct the k-d tree. This data structure splits the k-dimensional space (here k means k dimensions of space, don’t confuse this with k as a number of nearest neighbors!) and allows faster search for nearest points, since we “know where to look” in that space. You may think of it like a generalization of BST for many dimensions. It “cuts” space with axis-aligned cuts, dividing points into groups in children nodes.\nConstructing the k-d tree is not a machine learning task itself, since it stems from computational geometry domain, so we won’t cover this in detail, only on conceptual level. The time complexity is usually $O(d * n * log(n))$, because insertion is $O(log(n))$ (similar to regular BST) and we have n points from the training dataset, each with d dimensions. I assume the efficient implementation of the data structure, i. e. it finds the optimal split point (median in the dimension) in O(n), which is possible with the median of medians algorithm. Space complexity is $O(d * n)$ — note that it depends on dimensionality d, which makes sense, since more dimensions correspond to more space divisions and larger trees (in addition to larger time complexity for the same reason).\nAs for the prediction phase, the k-d tree structure naturally supports “k nearest point neighbors query” operation, which is exactly what we need for kNN. The simple approach is to just query k times, removing the point found each time — since query takes $O(log(n))$, it is $O(k * log(n))$ in total. But since the k-d tree already cuts space during construction, after a single query we approximately know where to look — we can just search the “surroundings” around that point. Therefore, practical implementations of k-d tree support querying for whole k neighbors at one time and with complexity $O(sqrt(n) + k)$, which is much better for larger dimensionalities, which are very common in machine learning.\nThe above complexities are the average ones, assuming the balanced k-d tree. The O(log(n)) times assumed above may degrade up to $O(n)$ for unbalanced trees, but if the median is used during the tree construction, we should always get a tree with approximately $O(log(n))$ insertion/deletion/search complexity.\nChoosing the method in practice To summarize the complexities: brute force is the slowest in the big O notation, while both k-d tree and ball tree have the same lower complexity. How do we know which one to use then?\nTo get the answer, we have to look at both training and prediction times, that’s why I have provided both. The brute force algorithm has only one complexity, for prediction, $O(k * n)$. Other algorithms need to create the data structure first, so for training and prediction they get $O(d * n * log(n) + k * log(n))$, not taking into account the space complexity, which may also be important. Therefore, where the construction of the trees is frequent, the training phase may outweigh their advantage of faster nearest neighbor lookup.\nShould we use k-d tree or ball tree? It depends on the data structure — relatively uniform or “well behaved” data will make better use of k-d tree, since the cuts of space will work well (near points will be close in the leaves after all cuts). For more clustered data the “balls” from the ball tree will reflect the structure better and therefore allow for faster nearest neighbor search. Fortunately, Scikit-learn supports “auto” option, which will automatically infer the best data structure from the data.\nLet’s see this in practice on two case studies, which I’ve encountered in practice during my studies and job.\nCase study 1: classification The more “traditional” application of the kNN is the classification of data. It often has quite a lot of points, e. g. MNIST has 60k training images and 10k test images. Classification is done offline, which means we first do the train ing phase, then just use the results during prediction. Therefore, if we want to construct the data structure, we only need to do so once. For 10k test images, let’s compare the brute force (which calculates all distances every time) and k-d tree for 3 neighbors:\nBrute force $(O(k * n))$: 3 * 10,000 = 30,000\nk-d tree $ (O(k * log(n)))$: 3 * log(10,000) ~ 3 * 13 = 39\nComparison: 39 / 30,000 = 0.0013\nAs you can see, the performance gain is huge! The data structure method uses only a tiny fraction of the brute force time. For most datasets this method is a clear winner.\nCase study 2: real-time smart monitoring Machine Learning is commonly used for image recognition, often using neural networks. It’s very useful for real-time applications, where it’s often integrated with cameras, alarms etc. The problem with neural networks is that they often detect the same object 2 or more times — even the best architectures like YOLO have this problem. We can actually solve it with nearest neighbor search with a simple approach:\n  Calculate the center of each bounding box (rectangle)\n  For each rectangle, search for its nearest neighbor (1NN)\n  If points are closer than the selected threshold, merge them (they detect the same object)\n  The crucial part is searching for the closest center of another bounding box (point 2). Which algorithm should be used here? Typically we have only a few moving objects on camera, maybe up to 30–40. For such a small number, speedup from using data structures for faster lookup is negligible. Each frame is a separate image, so if we wanted to construct a k-d tree for example, we would have to do so for every frame, which may mean 30 times per second — a huge cost overall. Therefore, for such situations a simple brute force method works fastest and also has the smallest space requirement (which, with heavy neural networks or for embedded CPUs in cameras, may be important).\nHow to choose a proper k? K-fold Cross Validation  Cross-validation is a statistical method used to estimate the skill of machine learning models.\n   Advantage: Can avoid overfitting and under-fitting\n  Disadvantage: K should be large enough\n  Reference\nFor complexity explanation\nFor three KNN algorithms\n","permalink":"/post/2022-01-25notek-nearest-neighbor-knn/","summary":"Summary of K Nearest Neighbor (KNN) algorithm.","title":"Notes|K Nearest Neighbor (KNN)"},{"content":"Lowercase and Uppercase str_1 = \u0026#34;Hello World\u0026#34; str_1.lower() # turn all characters to lowercase str_1.upper() # turn all characters to uppercase Replace str_1 = \u0026#34;Hello World\u0026#34; str_1.replace(\u0026#34; \u0026#34;, \u0026#34;\u0026#34;) # return \u0026#34;HelloWorld\u0026#34; ","permalink":"/post/2022-01-21cheatsheet-for-basic-python/","summary":"Some basic Python summary","title":"Notes|Cheatsheet for Basic Python"},{"content":"Reshape a matrix to the target dimensions given by n_rows and n_cols. np.reshape(mat, n_rows, n_cols) Returns the dot product of two matrices.  Dot product is also known as matrix multiplication.\n np.dot(mat_1, mat_2) # vector Returns the cross product of two matrices. np.cross(mat_1, mat_2) # This is what we multiply 2 matrix like (m x n) (n x m) Computes the inverse of a matrix. np.linalg.inv(mat) ","permalink":"/post/2022-01-21cheatsheet-for-basic-numpy-library/","summary":"Some basic Python Numby library summary","title":"Notes|Cheatsheet for Basic Python Numpy Library"},{"content":"Compute the number of unique entries in df. return len(df.column_name.unique()) Search for cells with specific value df[df[\u0026#39;column_name\u0026#39;] == \u0026#39;name\u0026#39;] Calculate the total number of missing values (they are NaN) in df. df.isnull().sum().sum() Combine 2 arrays res_3 = np.concatenate((res_1, res_2)) Correct misspelled names df_cars[\u0026#39;name\u0026#39;] = df_cars[\u0026#39;name\u0026#39;].str.replace(\u0026#39;chevroelt|chevrolet|chevy\u0026#39;,\u0026#39;chevrolet\u0026#39;) Replace NaN value df_cars.horsepower = df_cars.horsepower.str.replace(\u0026#39;?\u0026#39;,\u0026#39;NaN\u0026#39;).astype(float) Fill missing value meanhp = df_cars[\u0026#39;horsepower\u0026#39;].mean() df_cars[\u0026#39;horsepower\u0026#39;] = df_cars[\u0026#39;horsepower\u0026#39;].fillna(meanhp) Create Dummy Variables Values like ‘america’ cannot be read into an equation. So we create 3 simple true or false columns with titles equivalent to “Is this car America?”, “Is this care European?” and “Is this car Asian?”. These will be used as independent variables without imposing any kind of ordering between the three regions. Let’s apply the below code.\ncData = pd.get_dummies(df_cars, columns=[\u0026#39;origin\u0026#39;]) cData ","permalink":"/post/2022-01-21cheatsheet-for-basic-python-pandas-library/","summary":"Some basic Python Pandas library summary","title":"Notes|Cheatsheet for Basic Python Pandas Library"},{"content":"Machine Learning Supervised learning \u0026amp; Unsupervised learning Starting Point Outcome measurement $Y$ (Also dependent variable, response, target )\n In the regression problem, $Y$ is quantitative. In the classification problem, $Y$ takes values in a finite, unordered set.  Vector of $p$ predictor measurements $X$ (also called inputs, regressors, covariates, features, independent variables)\nUnsupervised Learning Starting Point  No outcome varibale, just a set of predictors (features) measured on a set of samples. Objective is more fuzzy - find groups of samples that behave similarly, find features that behave similarly, find linear combinations of features with the most variation. Difficult to know how well you are doing. Different from supervised learning, but can be useful as a pre-processing step for supervised learning or as an exploratory analysis tool  Our objectives  Accurately predict unseen test cases. Understand which inputs affect the outcome, and how. Access the quality of our predictions and inferences.  ML is to generalize knowledge beyond the training examples\nPhilosophy   It is important to understand the ideas behind the various techniques, in order to know how and when to use them.\n  One has to understand the simpler methods first, in order to grasp the more sophisticated ones.\n  It is important to accurately assess the performance of a method, to know how well or how badly it is working [simple methods often perform as well as fancier ones!]\n  Supervised learning : regression problems Find feature and response $X$(Independent variable, feature, covariate, input): TV, Radio, Newspaper\n$Y$(Dependent variable, target, response, output): Sales\nWe try to build a model: $$ \\text{Sales} \\approx f(\\text{TV, Radio, Newspaper}) $$ We can refer to the input vector collectively as: $$ X=\\left(\\begin{array}{l} X_{1} \\ X_{2} \\ X_{3} \\end{array}\\right) $$ Now we can write our model as: $$ Y=f(x) + \\varepsilon $$ $\\varepsilon$ captures measurement errors and other discrepancies.\nWhat is regression function? The ideal $f(x)=E(Y|X=x)$ Is called the regression function.\nWhat is our goal? $f(x)$ is optimal predictor of $Y$ with regard to mean-squared prediction error $$ \\text{Minimize}:E\\left[(Y-g(X))^{2} \\mid X=x\\right] $$\nHow to estimate $f$ ? Typically we have few if any data points with $X=4$ exactly, so we cannot compute $E(Y|X=x)$ !\nWhat we do is to relax the definition and let:\n$$ \\hat{f}(x)=\\operatorname{Ave}(Y \\mid X \\in \\mathcal{N}(x)) $$ where $\\mathcal{N}(x)$ is some neighborhood of $x$.\nBuild linear model $$ f_{L}(X)=\\beta_{0}+\\beta_{1} X_{1}+\\beta_{2} X_{2}+\\cdots+\\beta_{p} X_{p} $$\n  A linear model is specified in terms of $p+1$ parameters $\\beta_0,\\beta_1,\u0026hellip;,\\beta_p$\n  We estimate the parameters by fitting the model to training data\n  Although it is almost never correct, a linear model often serves as a good and interpretable approximation to the unknown true function $f(X)$\n  Interpretability and Flexibility  Why under-fitting is bad?  If a model is under-fitting, it means the model even cannot fit the training data, let alone the testing data or use it in real-world cases   Why over-fitting is bad?  Although the model can fit training data well, but it\u0026rsquo;s too \u0026ldquo;well\u0026rdquo;, we cannot use it in other cases.   How do we know when the fit is just right? Parsimony v.s. black box  We often prefer a simpler model involving fewer variables over a black-box predictor involving them all.    Accessing Model Accuracy Suppose we fit a model $\\hat{f}(x)$ to some training data $\\operatorname{Tr}=\\left{x_{i}, y_{i}\\right}_{1}^{n}$, and we wish to see how it performs.\nWe could compute the average squared prediction error over $\\text{Tr}$: $$ M S E_{T r}=A v e_{i \\in \\operatorname{Tr}}\\left[y_{i}-\\hat{f}\\left(x_{i}\\right)\\right]^{2} $$ And then we compute it using fresh test data $\\operatorname{Te}=\\left{x_{i}, y_{i}\\right}{1}^{n}$ : $$ M S E{T e}=A v e_{i \\in \\operatorname{Te}}\\left[y_{i}-\\hat{f}\\left(x_{i}\\right)\\right]^{2} $$ Black curve is truth. Red curve on right is $M S E_{T e}$. Grey curve is $M S E_{T r}$.\nOrange, blue and green curves/squares correspond to fits of different flexibility.\nChoose the flexibility based on average test error amounts to a bias-variance trade-off.\nSupervised learning : classification problems Here the response variable $Y$ is qualitative , e.g. email is one of $\\C = \\text{(spam, ham)}$, ham is good email ; digit class is one of $\\C = {0, 1, \u0026hellip;,9}$.\nOur goals  Build a classifier $C(X)$ That assigns a class label from $\\C$ to a future unlabeled observation $X$ Access the uncertainty in each classification Understand the roles of the different predictors among $X=X_1, X_2,\u0026hellip;,X_p$  Bayes optimal classifier Suppose the $K$ elements in $\\C$ Are numbered $1,2,\u0026hellip;,K$, Let: $$ p_k(x)=\\text{Pr}(Y=K|X=x),k=1,2,\u0026hellip;K $$ These are the conditional/posterior class probabilities at x. Suppose those class probabilities are known, the Bayes optimal classifier at $x$ is: $$ C(x)=j \\text { if } p_{j}(x)=\\max \\left{p_{1}(x), p_{2}(x), \\ldots, p_{K}(x)\\right} $$\n","permalink":"/post/2022-01-21notedata-mining-analysis-intro/","summary":"Some basic Python summary","title":"Note|Data Mining \u0026 Analysis Intro Ep.0"},{"content":"Create table CREATE TABLE TABLE_NAME (\u0026#34;CustomerID\u0026#34; INT, \u0026#34;PartySize\u0026#34; INT) Insert data INSERT INTO TABLE_NAME (ID, NUMBER) VALUES (123,81) INSERT INTO TABLE_NAME (ID, NUMBER) VALUES ((SELECT ID FROM COLUMN_NAME WHERE Email=\u0026#34;1232@GMAIL.com\u0026#34;), 4) Look for similarity SELECT C.FirstName, C.LastName, Reservation.Date FROM Reservation JOIN Customer AS C ON C.ID = Reservation.ID WHERE C.LastName LIKE \u0026#34;Ste%\u0026#34; Check availablity SELECT COUNT(Books.Title) FROM Loans JOIN Books ON Loads.BookID = Books.BookID WHERE Books.Title = \u0026#34;Dracula\u0026#34; AND Loans.ReturnedDate IS NULL Filter _ underscore: a single character wildcard.\n% percent sign: a wildcard for one or more characters.\n* asterisk: represents zero or more characters\nSQL string funcitons SUBSTR( string, start, length ) LENGTH( string ) TRIM( string) #Trimming is case sensitive.  LOWER (string) #Convert the text to lower-case SQL SUBSTR SELECT released, SUBSTR(released, 1, 4) AS Year, SUBSTR(released, 6, 2) AS Month, SUBSTR(released, 9, 2) AS Day, FROM album ORDER BY released SQL TRIM SELECT TRIM(\u0026#39; string \u0026#39;) SELECT LTRIM(\u0026#39; string \u0026#39;) SELECT RTRIM(\u0026#39; string \u0026#39;) SELECT LTRIM(\u0026#39;......string......\u0026#39;, \u0026#39;.\u0026#39;) Some tips   When INSERT data to a table, the unpopulated columns are given a null value rather than left blank.\n  When use DELETE, the asterisk is not necessary for the code to remove a row from a table.\n  E.g:\nDELETE FROM student WHERE id=3; How to just add a null row?  INSERT INTO TABLE_NAME DEFAULT VALUE How can a constraint be placed on a table where a field will contain the value \u0026ldquo;Mickey\u0026rdquo; if nothing is provided?  CREATE TABLE People (FirstName TEXT DEFAULT \u0026#39;Mickey\u0026#39;, address TEXT, city TEXT); Set an ID column  CREATE TABLE vehicles (VehicleID INTEGER PRIMARY KEY); Which constraint ensures a column cannot have any duplicate values including null values?  UNIQUE NOT NULL\n Alphabetical order: Z is the highest, and \u0026ldquo;A\u0026rdquo; is the lowest.\n  To what does a table schema refer: the number of, titles for, and data types in columns\n  Correct way to represent a string\n  SELECT \u0026#39;Karen\u0026#39;\u0026#39;s Classroom\u0026#39;; Two single quotes are used to represent one apostrophe and strings are represented in single quotes.\n SQLite compares data based on case, so is it important to convert all fields to the same case.\n  What is the standard way to concatenate two strings?\n  Standard : ||\nMySQL: CONCAT()\nWhich option is an example of SQL syntax to add one day to the current day?  SELECT DATETIME(\u0026#39;now\u0026#39;, \u0026#39;+1 day\u0026#39;); WHERE is used to filter non-aggregation data, HAVING is used to filter aggregation data. How transactions handled within a database: If any of the operations fail, then the entire group of operations fail. What does the CRUD operations acronym stand for?  Create, Read, Update and Delete.\nReferences LinkedIn Learning - SQL Code Challenges\n","permalink":"/post/2022-01-19cheatsheet-for-basic-sql/","summary":"Some basic SQL code summary","title":"Notes|Cheatsheet for Basic SQL Code"},{"content":"What Data Analyst Should be Able to Do  Use the tools to analyze a real world dataset Intepret the findings and develop new methods to analyze a given dataset Know the limitations of your analysis and communicate it Understand how to use novel methods, and their limitations  ","permalink":"/post/2022-01-19what-data-analyst-should-be-able-to-do/","summary":"Four main points for a qualified data analyst should be able to do.","title":"Notes|What A Qualified Data Analyst Should be Able to Do"},{"content":"年轻就是不断地试错，试着把人生当做一个不断遭遇各种课题，然后不断解决、不断成长的过程。在整个过程中，可以把人生的每一段经历都转化成资源。《被讨厌的勇气》这本书里说：\n 经历本身不会决定什么。我们给过去的经历赋予了什么样的意义，这直接决定了我们的生活。人生不是别人赋予的，而是由自己选择的，是自己选择自己如何生活。\n ","permalink":"/chn/2022-01-16%E4%B8%BA%E8%87%AA%E5%B7%B1%E7%9A%84%E4%BA%BA%E7%94%9F%E8%B4%9F%E8%B4%A3/","summary":"经历本身不会决定什么。我们给过去的经历赋予了什么样的意义，这直接决定了我们的生活。","title":"为自己的人生负责"},{"content":"What is Data Visualization? So, you probably think data visualization is just some bars and lines, since everyone seems to know how to draw and use matplotlib library in Python.\nIs these data visualization? Yes, but there could be more.\n The greatest value of a picture is when it forces us to notice what we never expected to see.\n\u0026mdash; John Tukey\n Let\u0026rsquo;s see some famous statistical graphics in our history.\nFig.1 Exports and Imports to and from DENMARK \u0026amp; NORWAY from 1700 to 1780 This figure credits to WIKIPEIDA-William Playfair, in this figure it clearly shows the imports and exports data from 1700 to 1780 of England, at a glance we can know which year has a trade surplus and which has a trade deficit. By the way, William Playfair is also the father of pie chart.\nFig.2 How John Snow traced the source of a cholera outbreak in Soho, London in 1854 In 19th Century of London, the city was a nightmare to human due to lack of clean water and sewage system, trash piled up everywhere in the city. On the other hand, it was heaven for epidemic. In Soho, London, 1854, there was an outbreak of cholera. At that time the germ theory of disease had not yet been developed. Most people thought cholera was caused by the foul air. Doctor John Snow was quite skeptical about the \u0026ldquo;pollution air theory\u0026rdquo;, he decided to conduct his own investigation. By talking to local residents, he identified the true reason was in the public water pump even though his chemical and microscope examination of a water sample from the water pump did not conclusively prove its danger. The reason behind this is because the obvious geographical pattern in his figure.\nFig.3 Figure of the causes of mortality in the army in the East by Florence Nightingale. Florence Nightingale was an English social reformer, statistician and the founder of modern nursing. Nightingale is described as \u0026ldquo;a true pioneer in the graphical representation of statistics\u0026rdquo;, and is credited with developing a form of the pie chart now known as the polar area diagram (rose diagram) shown in fig.3.\nIn fig.3, blue color measures deaths from predictable diseases, red color measures deaths from wounds, and black color measures deaths from all other reasons. She successfully persuaded the Government of the United Kingdom to improve medical care and health service for the army, after 10 years of sanitary reform, mortality among the soldiers in India had declined from 69 to 18 per 1,000.\nNowadays, data visualization can be more. Credit to Obsidian\nCredit to 1point3acres\n Data Visualization is the creation and study of the visual representation of data.\n\u0026mdash; WIKIPEDIA\n Three Types of Data Visualization  Information visualization Scientific visualization Visual analytics  Information visualization Information visualization is the study of visual representations of abstract data to reinforce human cognition.\nAbove figure shows how people in a team (designer, editor and data analyst) make an infographic.\nCredit to Wikiwand\nScientific visualization Scientific visualization is an interdisciplinary branch of science concerned with the visualization of scientific phenomena. It is also considered a subset of computer graphics, a branch of computer science. The purpose of scientific visualization is to graphically illustrate scientific data to enable scientists to understand, illustrate, and glean insight from their data.\nCredit to Wikiwand\nVisual Analytics Visual analytics is an outgrowth of the fields of information visualization and scientific visualization that focuses on analytical reasoning facilitated by interactive visual interfaces.\nCredit to Washington State Department of Health\nHot Topics And Trends of Data Visualization Foundations of Data Visualization There are three basic elements of data visualization.\n Process of data visualization Data model Visual coding  Process of Data Visualization Data Model   Categorical data\n Gender: male, female in general Size of clothes: small, medium, large    Ordinal data (is kind of categorical data, but it is ordinal)\n First prize, second prize, and third prize Elementary school, middle school, high school    Numerical data\n With specific number to describe  Categorical data and ordinal data can be attributed to qualitative data, numerical data can be attributed to quantitative data.\nVisual coding   Reference geekplux.com\n","permalink":"/post/2022-01-15what-i-think-data-visualization-is-in-2022/","summary":"What I think is data visualization, some hot tpoics and trends","title":"What I Think Data Visualization Is in 2022"},{"content":"So today when I swiped twitter, I found an interesting tweet which was @yihong0618 made a Python tool can generate a svg heatmap GitHubPoster.\nHere is my 2018-2022 YouTube heatmap\nIn 2017 Fall I became a college student, after that I had more time to explore things that piqued my interests. But I was in China at that time, YouTube was blocked as many other apps did. But I still managed to use YouTube and other apps like Twitter and Google when I was a sophomore student.\n","permalink":"/post/2022-01-11my-youtube-2018-2022-watch-history-in-a-heatmap/","summary":"Heatmap can show a lot","title":"My YouTube 2018-2022 Watch History in A Heatmap Using GitHubPoster"},{"content":"1. Unique Email Addresses From 929. Unique Email Addresses\n1.1 Problem Description Every valid email consists of a local name and a domain name, separated by the '@'sign. Besides lowercase letters, the email may contain one or more '.' or '+'.\n For example, in \u0026quot;alice@leetcode.com\u0026quot;, \u0026quot;alice\u0026quot; is the local name, and \u0026quot;leetcode.com\u0026quot; is the domain name.  If you add periods '.' between some characters in the local name part of an email address, mail sent there will be forwarded to the same address without dots in the local name. Note that this rule does not apply to domain names.\n For example, \u0026quot;alice.z@leetcode.com\u0026quot; and \u0026quot;alicez@leetcode.com\u0026quot; forward to the same email address.  If you add a plus '+' in the local name, everything after the first plus sign will be ignored. This allows certain emails to be filtered. Note that this rule does not apply to domain names.\n For example, \u0026quot;m.y+name@email.com\u0026quot; will be forwarded to \u0026quot;my@email.com\u0026quot;.  It is possible to use both of these rules at the same time.\nGiven an array of strings emails where we send one email to each emails[i], return the number of different addresses that actually receive mails.\n1.2 Solution We can use split() and replace here:\n split() is to split email address using @ as identifier replace is to use \u0026quot;\u0026quot; to replace .  class Solution: def numUniqueEmails(self, emails: List[str]) -\u0026gt; int: actual = set() for email in emails: local, domain = email.split(\u0026#39;@\u0026#39;) local = local.split(\u0026#39;+\u0026#39;)[0].replace(\u0026#39;.\u0026#39;, \u0026#39;\u0026#39;) actual.add((local, domain)) return len(actual) 2. Day of the Year From 1154. Day of the Year\n2.1 Problem Description Given a string date representing a Gregorian calendar date formatted as YYYY-MM-DD, return the day number of the year.\nA leap year:\n can be divided by 4, 400 cannot be divided by 100  2.2 Solution class Solution: def dayOfYear(self, date: str) -\u0026gt; int: # data\u0026#39;s type is string, we want to 1)split it into 3 prats: year, month, day; 2) type from string to int # we can use map() y, m, d = map(int, date.split(\u0026#39;-\u0026#39;)) days = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31] if (y % 400) == 0 or ((y % 4 == 0) and (y % 100 != 0)): days[1] = 29 return d + sum(days[:m-1]) 3. Rotate String From 796. Rotate String\n3.1 Problem Description Given two strings s and goal, return true if and only if s can become goal after some number of shifts on s.\nA shift on s consists of moving the leftmost character of s to the rightmost position.\n For example, if s = \u0026quot;abcde\u0026quot;, then it will be \u0026quot;bcdea\u0026quot; after one shift.  Example 1:\nInput: s = \u0026#34;abcde\u0026#34;, goal = \u0026#34;cdeab\u0026#34; Output: true Example 2:\nInput: s = \u0026#34;abcde\u0026#34;, goal = \u0026#34;abced\u0026#34; Output: false 3.2 Solution One easy way to solve this problem is we can find out that string goal is also in s + s if goal is rotated from s.\nclass Solution: def rotateString(self, s: str, goal: str) -\u0026gt; bool: return len(s) == len(goal) and goal in s + s 4. Most Common Word From 819. Most Common Word\n4.1 Problem Description Given a string paragraph and a string array of the banned words banned, return the most frequent word that is not banned. It is guaranteed there is at least one word that is not banned, and that the answer is unique.\nThe words in paragraph are case-insensitive and the answer should be returned in lowercase.\nExample 1:\nInput: paragraph = \u0026#34;Bob hit a ball, the hit BALL flew far after it was hit.\u0026#34;, banned = [\u0026#34;hit\u0026#34;] Output: \u0026#34;ball\u0026#34; Explanation: \u0026#34;hit\u0026#34; occurs 3 times, but it is a banned word. \u0026#34;ball\u0026#34; occurs twice (and no other word does), so it is the most frequent non-banned word in the paragraph. Note that words in the paragraph are not case sensitive, that punctuation is ignored (even if adjacent to words, such as \u0026#34;ball,\u0026#34;), and that \u0026#34;hit\u0026#34; isn\u0026#39;t the answer even though it occurs more because it is banned. 4.2 Solution 4 steps:\n remove all punctuations change to lowercase words count for each word not in banned set return the most common word  class Solution: def mostCommonWord(self, paragraph: str, banned: List[str]) -\u0026gt; str: ban = set(banned) # \\w: Matches Unicode word characters, + means Repetition qualifiers words = re.findall(r\u0026#39;\\w+\u0026#39;, paragraph.lower()) print(words) # most_common(n most common elements) return collections.Counter(w for w in words if w not in ban).most_common(1)[0][0] ","permalink":"/post/2022-01-05leetcodepython-some-string-problems/","summary":"Leetcode problems about string","title":"Leetcode|Python Some String Problems"},{"content":"I just finished my 16Personalities Test, and it told me I am one of the protagonists(ENFJs).\n Protagonists (ENFJs) feel called to serve a greater purpose in life. Thoughtful and idealistic, these personality types strive to have a positive impact on other people and the world around them. They rarely shy away from an opportunity to do the right thing, even when doing so is far from easy.\n I cannot say all of these results are correct, but most of them are. And in this post I want to share the connection between my personality type and my career path.\nI can use some keywords to describe my ideal job:\n Tech related field; Can ommunicate to people, people-oriented field in other words; Can help others, a meaning job in other words;  My 16Personalities Test tells what I love most is helping other people:\n When it comes to choosing a career, Protagonists (ENFJs) find fulfillment in doing what they love most – helping other people. And with their creativity and drive, they can find ways to serve and uplift others in nearly any work environment, whether they’re behind a gleaming table in a corporate boardroom or behind the counter at a beloved local coffee shop.\n I guess above is why I want to work in data-related field and now I am actively tring to find an Data Analytics/Data Engineer internship.\n","permalink":"/post/2022-01-08my-16personalities-test-results-is-enfj/","summary":"Summary of My 16Personalities Test Results","title":"My 16Personalities Test Results is ENFJ"},{"content":"现在许多所谓的“正能量”，就是无视苦难，无视丑陋，无视一切的不平等，用粉饰的美梦和自以为是的光明来装点和迎合自己浅薄的脑袋。 还好，明白人越来越多，越来越多的人识破了那些“正能量”是什么玩意儿。他们只在安全的时候勇敢，只在免费的时候慷慨。\n","permalink":"/chn/2022-01-06%E6%AD%A3%E8%83%BD%E9%87%8F/","summary":"他们只在安全的时候勇敢，只在免费的时候慷慨。","title":"正能量"},{"content":"1. Convert Binary Number in a Linked List to Integer From 1290. Convert Binary Number in a Linked List to Integer\n1.1 Problem Description Given head which is a reference node to a singly-linked list. The value of each node in the linked list is either 0 or 1. The linked list holds the binary representation of a number.\nReturn the decimal value of the number in the linked list.\nExample\nInput: head = [1,0,1] Output: 5 Explanation: (101) in base 2 = (5) in base 10 1.2 Solution  Try to store head value in string format Then use int() method to turn binary to decimal  class Solution: def getDecimalValue(self, head: ListNode) -\u0026gt; int: #create str s to store value s = \u0026#34;\u0026#34; # while loop until linked list ends while head: s += str(head.val) head = head.next return int(s,2) #base is 2, binary to decimal  2. Middle of the Linked List From 876. Middle of the Linked List\n2.1 Problem Description Given the head of a singly linked list, return the middle node of the linked list.\nIf there are two middle nodes, return the second middle node.\nExample\nInput: head = [1,2,3,4,5] Output: [3,4,5] Explanation: The middle node of the list is node 3. 2.2 Solution A smart way is to use 2 pointers, slow and fast, each time slow goes 1 step while fast goes 2 step, hence when fast hits the end, slow will point to the middle of the linked list.\ndef middleNode(self, head: Optional[ListNode]) -\u0026gt; Optional[ListNode]: # create 2 pointers slow = fast = head # while fast has not hit the end while fast and fast.next: slow = slow.next fast = fast.next.next # slow will point the middle of the linked list return slow 3. \u0026ldquo;Delete\u0026rdquo; Node in a Linked List From 237. Delete Node in a Linked List\n3.1 Problem Description Write a function to delete a node in a singly-linked list. You will not be given access to the head of the list, instead you will be given access to the node to be deleted directly.\nIt is guaranteed that the node to be deleted is not a tail node in the list.\nExample\nInput: head = [4,5,1,9], node = 5 Output: [4,1,9] Explanation: You are given the second node with value 5, the linked list should become 4 -\u0026gt; 1 -\u0026gt; 9 after calling your function. 3.2 Solution Actually you can not really delete a node, you just skip this node and point to the next.\nclass Solution: def deleteNode(self, node): \u0026#34;\u0026#34;\u0026#34; :type node: ListNode :rtype: void Do not return anything, modify node in-place instead. \u0026#34;\u0026#34;\u0026#34; node.val = node.next.val node.next = node.next.next 4. Reverse Linked List From 206. Reverse Linked List\n4.1 Problem Description Given the head of a singly linked list, reverse the list, and return the reversed list.\nExample\nInput: head = [1,2,3,4,5] Output: [5,4,3,2,1] 4.2 Solution The idea is to give next value to previous value.\nclass Solution: def reverseList(self, head: Optional[ListNode]) -\u0026gt; Optional[ListNode]: cur, prev = head, None while cur: cur.next, prev, cur = prev, cur, cur.next return prev 5. Palindrome Linked List From 234. Palindrome Linked List\n5.1 Problem Description Given the head of a singly linked list, return true if it is a palindrome.\nExample\nInput: head = [1,2,2,1] Output: true 5.2 Solution We can combine what we learned in 206. Reverse Linked List, first we try to get the reverse first half of linked list using slow and fast pointers, and then compare the value of the first half linked list with the second half of the linked list.\ndef isPalindrome(self, head): fast = slow = head # find the mid node, slow will point to the mid node while fast and fast.next: fast = fast.next.next slow = slow.next # reverse the second half node = None while slow: nxt = slow.next slow.next = node node = slow slow = nxt # compare the first and second half nodes while node: # while node and head: if node.val != head.val: return False node = node.next head = head.next return True 6. Linked List Cycle From 141. Linked List Cycle\n6.1 Problem Description Given head, the head of a linked list, determine if the linked list has a cycle in it.\nThere is a cycle in a linked list if there is some node in the list that can be reached again by continuously following the next pointer. Internally, pos is used to denote the index of the node that tail\u0026rsquo;s next pointer is connected to. Note that pos is not passed as a parameter.\nReturn true if there is a cycle in the linked list. Otherwise, return false.\nExample\n6.2 Solution The idea is similar to 876. Middle of the Linked List, we can use slow and fast pointers to tackle this problem.\nclass Solution: def hasCycle(self, head: Optional[ListNode]) -\u0026gt; bool: try: slow = head fast = head.next while slow is not fast: slow = slow.next fast = fast.next.next return True except: return False ","permalink":"/post/2022-01-05leetcodepython-linked-list-column/","summary":"Couple of leetcode problems related to linked list","title":"Leetcode|Python Linked List Column"},{"content":"From Leetcode 856 Score of Parentheses \n1. Problem Description Given a balanced parentheses string s, return the score of the string. The score of a balanced parentheses string is based on the following rule:\n  \u0026quot;()\u0026quot; has score 1. AB has score A + B, where A and B are balanced parentheses strings. (A) has score 2 * A, where A is a balanced parentheses string.   1.1 Solution we use stack to solve this problem:\n If there is a (, we add it to stack because it must match with a ) to get valid value back; If there is a ), we can try to match it with the top value in stack: we can either +1 or *2, here is a tricky way to tackle it: we always choose the greater one : (2 * last) or 1  def scoreOfParentheses(self, s: str) -\u0026gt; int: # Create stack stack = [0] for c in s: if c == \u0026quot;(\u0026quot;: stack.append(0) else: last = stack.pop() stack[-1] += (2 * last) or 1 print(stack) return stack[-1] ","permalink":"/post/2022-01-14leetcodepython-856-score-of-parentheses/","summary":"Use stack to tackle this type of matching problem","title":"Leetcode|Python 856 Score of Parentheses"},{"content":"Basic data type: Double String Logic\nIf the items are not of the same type, they are coerced:\nstring \u0026lt;-- numeric \u0026lt;-- logical\nnegative indexes (used for exclusion)\nAutomatic vector extension makes vectors very different from matrices and arrays, for which automatic extension does not exist.\nLists are sequences of anything. They can contain:\nbasic data types, vectors, matrices, arrays, lists (recursion),\u0026hellip;\nCreate a vector consisting of the numbers 1 to N, where 1 appears once, 2 appears twice, 3 appears 3 times,\u0026hellip; rep(1:x, 1:x) Reshape vector into a matrix in two ways (arranged by row and column) matrix(0:1, nrow=3, ncol=4, byrow=T) # if want to arrange by column, just without the \u0026#34;byrow\u0026#34; part [,1] [,2] [,3] [,4] [1,] 0 1 0 1 [2,] 0 1 0 1 [3,] 0 1 0 1 Select rows of a matrix in R that meet a condition car_models \u0026lt;- ``c``(``\u0026#39;Maruti\u0026#39;``,``\u0026#39;Hyundai\u0026#39;``,``\u0026#39;Tata\u0026#39;``, ``\u0026#39;Ford\u0026#39;``,``\u0026#39;Nissan\u0026#39;``,``\u0026#39;Toyota\u0026#39;``) car_type \u0026lt;- ``c``(``\u0026#39;Diesel\u0026#39;``,``\u0026#39;Petrol\u0026#39;``,``\u0026#39;Petrol\u0026#39;``, ``\u0026#39;Diesel\u0026#39;``,``\u0026#39;Petrol\u0026#39;``,``\u0026#39;Diesel\u0026#39;``) car_color \u0026lt;- ``c``(``\u0026#39;Red\u0026#39;``,``\u0026#39;Blue\u0026#39;``,``\u0026#39;Red\u0026#39;``, ``\u0026#39;Red\u0026#39;``,``\u0026#39;Blue\u0026#39;``,``\u0026#39;Red\u0026#39;``) year \u0026lt;- ``c``(2001,2011,2013,2012,2021,2021) # Storing matrix in mat (variable) mat \u0026lt;- ``cbind``(car_models,car_type,car_color,year) # condition to select only rows with # color = Red mat \u0026lt;- mat[mat[,``\u0026#34;car_color\u0026#34;``]==``\u0026#34;Red\u0026#34;``,] # displaying the resultant matrix mat car_models car_type car_color year [1,] \u0026#34;Maruti\u0026#34; \u0026#34;Diesel\u0026#34; \u0026#34;Red\u0026#34; \u0026#34;2001\u0026#34; [2,] \u0026#34;Tata\u0026#34; \u0026#34;Petrol\u0026#34; \u0026#34;Red\u0026#34; \u0026#34;2013\u0026#34; [3,] \u0026#34;Ford\u0026#34; \u0026#34;Diesel\u0026#34; \u0026#34;Red\u0026#34; \u0026#34;2012\u0026#34; [4,] \u0026#34;Toyota\u0026#34; \u0026#34;Diesel\u0026#34; \u0026#34;Red\u0026#34; \u0026#34;2021\u0026#34; ","permalink":"/post/2022-01-24noter-for-data-analysis-intro/","summary":"Basic data type: Double String Logic\nIf the items are not of the same type, they are coerced:\nstring \u0026lt;-- numeric \u0026lt;-- logical\nnegative indexes (used for exclusion)\nAutomatic vector extension makes vectors very different from matrices and arrays, for which automatic extension does not exist.\nLists are sequences of anything. They can contain:\nbasic data types, vectors, matrices, arrays, lists (recursion),\u0026hellip;\nCreate a vector consisting of the numbers 1 to N, where 1 appears once, 2 appears twice, 3 appears 3 times,\u0026hellip; rep(1:x, 1:x) Reshape vector into a matrix in two ways (arranged by row and column) matrix(0:1, nrow=3, ncol=4, byrow=T) # if want to arrange by column, just without the \u0026#34;byrow\u0026#34; part [,1] [,2] [,3] [,4] [1,] 0 1 0 1 [2,] 0 1 0 1 [3,] 0 1 0 1 Select rows of a matrix in R that meet a condition car_models \u0026lt;- ``c``(``\u0026#39;Maruti\u0026#39;``,``\u0026#39;Hyundai\u0026#39;``,``\u0026#39;Tata\u0026#39;``, ``\u0026#39;Ford\u0026#39;``,``\u0026#39;Nissan\u0026#39;``,``\u0026#39;Toyota\u0026#39;``) car_type \u0026lt;- ``c``(``\u0026#39;Diesel\u0026#39;``,``\u0026#39;Petrol\u0026#39;``,``\u0026#39;Petrol\u0026#39;``, ``\u0026#39;Diesel\u0026#39;``,``\u0026#39;Petrol\u0026#39;``,``\u0026#39;Diesel\u0026#39;``) car_color \u0026lt;- ``c``(``\u0026#39;Red\u0026#39;``,``\u0026#39;Blue\u0026#39;``,``\u0026#39;Red\u0026#39;``, ``\u0026#39;Red\u0026#39;``,``\u0026#39;Blue\u0026#39;``,``\u0026#39;Red\u0026#39;``) year \u0026lt;- ``c``(2001,2011,2013,2012,2021,2021) # Storing matrix in mat (variable) mat \u0026lt;- ``cbind``(car_models,car_type,car_color,year) # condition to select only rows with # color = Red mat \u0026lt;- mat[mat[,``\u0026#34;car_color\u0026#34;``]==``\u0026#34;Red\u0026#34;``,] # displaying the resultant matrix mat car_models car_type car_color year [1,] \u0026#34;Maruti\u0026#34; \u0026#34;Diesel\u0026#34; \u0026#34;Red\u0026#34; \u0026#34;2001\u0026#34; [2,] \u0026#34;Tata\u0026#34; \u0026#34;Petrol\u0026#34; \u0026#34;Red\u0026#34; \u0026#34;2013\u0026#34; [3,] \u0026#34;Ford\u0026#34; \u0026#34;Diesel\u0026#34; \u0026#34;Red\u0026#34; \u0026#34;2012\u0026#34; [4,] \u0026#34;Toyota\u0026#34; \u0026#34;Diesel\u0026#34; \u0026#34;Red\u0026#34; \u0026#34;2021\u0026#34; ","title":""},{"content":"Who I am Howdy! I am a postgrad at the Texas A\u0026amp;M University in Department of Industrial \u0026amp; Systems Engineering, Data Science track. I\u0026rsquo;ve previously lived in Beijing where I got my bachelor\u0026rsquo;s degree.\nI enjoy all the covenience and sparks brought by the digital world, and I’m always in search of methods to improve productivity. \u0026ldquo;Knowledge increases by spreading\u0026rdquo; sways my life so deeply, this saying pushes me to become a newsletter writer, a SSPAI writer, a Bilibili UP (kind of like youtuber in China) with 56K subscribers and 3.24 million views. I am still new, I still have a lot need to learn, I still have a long way to go, but I firmly believe all these learning snippets will rack up to a big amount someday.\nPersonalities  16Personalities: Protagonist Personality, ENFJ (Outgoing/Encouraging/Organized/People Person).  ","permalink":"/about/","summary":"About landisland This section details what he does \u0026amp; everything else you might want to know about him.","title":"About Me"}]